{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "09f12d29-31c0-499b-b15c-28b07b810928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GeneratedReviewsDetection'...\n",
            "remote: Enumerating objects: 256, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 256 (delta 86), reused 81 (delta 38), pack-reused 100\u001b[K\n",
            "Receiving objects: 100% (256/256), 109.27 MiB | 32.44 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/congruiyS2023/GeneratedReviewsDetection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r GeneratedReviewsDetection/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL-qLL3hBk_m",
        "outputId": "ee396092-7d60-40ef-9e89-6f204380f0f3"
      },
      "id": "vL-qLL3hBk_m",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.25.0 (from -r GeneratedReviewsDetection/requirements.txt (line 1))\n",
            "  Downloading transformers-4.25.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.12 (from -r GeneratedReviewsDetection/requirements.txt (line 2))\n",
            "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.22 (from -r GeneratedReviewsDetection/requirements.txt (line 3))\n",
            "  Downloading scikit-learn-0.22.tar.gz (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas==1.3.5 (from -r GeneratedReviewsDetection/requirements.txt (line 4))\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.7.3 (from -r GeneratedReviewsDetection/requirements.txt (line 5))\n",
            "  Downloading xgboost-1.7.3-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext==0.10.0 (from versions: 0.1.1, 0.2.0, 0.2.1, 0.2.3, 0.3.1, 0.4.0, 0.5.0, 0.6.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.1, 0.15.2, 0.16.0, 0.16.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext==0.10.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.25.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2QEVeI5Bo_p",
        "outputId": "fda407a1-fb62-49b4-86a2-a1b5b6071786"
      },
      "id": "Y2QEVeI5Bo_p",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.25.0\n",
            "  Using cached transformers-4.25.0-py3-none-any.whl (5.8 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.0) (2023.7.22)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'transformers' candidate (version 4.25.0 at https://files.pythonhosted.org/packages/2b/a6/b32ba581c064276dc254a4c2bdf5301a942fa28a4a9b41209d8909da37d2/transformers-4.25.0-py3-none-any.whl (from https://pypi.org/simple/transformers/) (requires-python:>=3.7.0))\n",
            "Reason for being yanked: Version was not properly set\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "U8sGZewlrbLf",
        "outputId": "34da5960-289d-4e55-cc8b-890b305bfe71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "U8sGZewlrbLf",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/GeneratedReviewsDetection && mkdir data\n",
        "!cp \"/content/GeneratedReviewsDetection/Data/Chinese Reviews/labeled_chinese_reviews.csv\" /content/GeneratedReviewsDetection/data/train.csv"
      ],
      "metadata": {
        "id": "B9iLc0X-v1tn"
      },
      "id": "B9iLc0X-v1tn",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd GeneratedReviewsDetection && python3 src/split.py"
      ],
      "metadata": {
        "id": "ixODk982wC56"
      },
      "id": "ixODk982wC56",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/GeneratedReviewsDetection && mkdir data\n",
        "!cd /content/GeneratedReviewsDetection && unzip \"./Data/Chinese Reviews/labeled_chinese_reviews_train.csv.zip\" -d ./data && mv ./data/labeled_chinese_reviews_train.csv ./data/train_val.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NugvJ3OFBsS0",
        "outputId": "8425d681-1e1d-4670-b847-547e02897098"
      },
      "id": "NugvJ3OFBsS0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./Data/Chinese Reviews/labeled_chinese_reviews_train.csv.zip\n",
            "  inflating: ./data/labeled_chinese_reviews_train.csv  \n",
            "  inflating: ./data/__MACOSX/._labeled_chinese_reviews_train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/GeneratedReviewsDetection/Data/Chinese Reviews/labeled_chinese_reviews.csv\" /content/GeneratedReviewsDetection/data/val_val.csv"
      ],
      "metadata": {
        "id": "FbNxO0TrDNxP"
      },
      "id": "FbNxO0TrDNxP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/GeneratedReviewsDetection && python3 ./src/train.py --model_version \"Langboat/mengzi-gpt-neo-base\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAB2MPPuC6to",
        "outputId": "0b34f8e3-c708-42c0-9a0d-d82085dfaaea"
      },
      "id": "jAB2MPPuC6to",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-30 01:06:02.873572: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-30 01:06:02.873636: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-30 01:06:02.873689: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-30 01:06:02.891895: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-30 01:06:04.884246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at Langboat/mengzi-gpt-neo-base and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Backbone type: Langboat/mengzi-gpt-neo-base\n",
            "Training on device:  cuda\n",
            "Learning rate: 0.0001\n",
            "EPOCH: 1..\n",
            "Training..\n",
            "Processed 500th batch..\n",
            "Processed 1000th batch..\n",
            "Processed 1500th batch..\n",
            "Processed 2000th batch..\n",
            "Processed 2500th batch..\n",
            "Processed 3000th batch..\n",
            "Testing..\n",
            "Prediction metrics at 0.5: \n",
            "Accuracy: 0.98\n",
            "Precision: 1.0\n",
            "Recall: 0.9595959595959596\n",
            "\n",
            "Prediction metrics at Youden 0.11800000071525574: \n",
            "Accuracy J: 0.995\n",
            "Precision J: 0.9974619289340102\n",
            "Recall J: 0.9924242424242424\n",
            "Found best accuracy. Saving to disk.\n",
            "\n",
            "EPOCH: 2..\n",
            "Training..\n",
            "Processed 500th batch..\n",
            "Processed 1000th batch..\n",
            "Processed 1500th batch..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/GeneratedReviewsDetection && python3 /content/GeneratedReviewsDetection/src/dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJzfXCpoE6mc",
        "outputId": "bc18f7bb-776c-4d7c-9eb0-5aecfe3fd32f"
      },
      "id": "gJzfXCpoE6mc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 22:08:21.000588: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 22:08:21.000641: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 22:08:21.000675: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 22:08:21.008612: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-29 22:08:22.078827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "{'input': [[27946, 2226, 3332, 12, 7, 11975, 2216, 1314, 3899, 3, 7036, 3332, 591, 5151, 193, 4, 1306, 9855, 11739, 401, 2235, 2226, 911, 3, 217, 299, 2499, 1047, 190, 4, 2209, 1735, 555, 473, 1659, 9075, 44524, 119, 7522, 2984, 24705, 3, 655, 6128, 12766, 1041, 4585, 4]], 'label': 1}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}