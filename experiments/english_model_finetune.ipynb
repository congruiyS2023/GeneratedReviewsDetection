{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id",
        "outputId": "5a3b47ca-84e0-40ab-8a11-5984a759895b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GeneratedReviewsDetection'...\n",
            "remote: Enumerating objects: 242, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 242 (delta 78), reused 74 (delta 35), pack-reused 100\u001b[K\n",
            "Receiving objects: 100% (242/242), 109.27 MiB | 37.69 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/congruiyS2023/GeneratedReviewsDetection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r GeneratedReviewsDetection/requirements.txt"
      ],
      "metadata": {
        "id": "shAjiAtJYJm1",
        "outputId": "323fb9d8-b5c6-4e93-c647-3d79a107abee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "shAjiAtJYJm1",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.25.0 (from -r GeneratedReviewsDetection/requirements.txt (line 1))\n",
            "  Downloading transformers-4.25.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.12 (from -r GeneratedReviewsDetection/requirements.txt (line 2))\n",
            "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.22 (from -r GeneratedReviewsDetection/requirements.txt (line 3))\n",
            "  Downloading scikit-learn-0.22.tar.gz (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas==1.3.5 (from -r GeneratedReviewsDetection/requirements.txt (line 4))\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.7.3 (from -r GeneratedReviewsDetection/requirements.txt (line 5))\n",
            "  Downloading xgboost-1.7.3-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext==0.10.0 (from versions: 0.1.1, 0.2.0, 0.2.1, 0.2.3, 0.3.1, 0.4.0, 0.5.0, 0.6.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.1, 0.15.2, 0.16.0, 0.16.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext==0.10.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "qmQ66zzxZEwV",
        "outputId": "39fc6263-b4a1-4830-fb06-94a4c1aea9a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qmQ66zzxZEwV",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.2/1.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.25.0"
      ],
      "metadata": {
        "id": "HZtLjNPHYT7X",
        "outputId": "8870adcc-df2a-48f3-dbee-2afaa5e6f64b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HZtLjNPHYT7X",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.25.0\n",
            "  Using cached transformers-4.25.0-py3-none-any.whl (5.8 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.0) (2023.7.22)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'transformers' candidate (version 4.25.0 at https://files.pythonhosted.org/packages/2b/a6/b32ba581c064276dc254a4c2bdf5301a942fa28a4a9b41209d8909da37d2/transformers-4.25.0-py3-none-any.whl (from https://pypi.org/simple/transformers/) (requires-python:>=3.7.0))\n",
            "Reason for being yanked: Version was not properly set\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/GeneratedReviewsDetection && mkdir data\n",
        "!cd /content/GeneratedReviewsDetection && unzip \"./Data/English Reviews/labeled_english_reviews_train.csv.zip\" -d ./data && mv ./data/labeled_english_reviews_train.csv ./data/train_val.csv"
      ],
      "metadata": {
        "id": "3fuHNsTFYWsH",
        "outputId": "0e2a4417-20b6-40ea-f5bc-d0c992f1f0d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3fuHNsTFYWsH",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./Data/English Reviews/labeled_english_reviews_train.csv.zip\n",
            "  inflating: ./data/labeled_english_reviews_train.csv  \n",
            "  inflating: ./data/__MACOSX/._labeled_english_reviews_train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/GeneratedReviewsDetection/Data/English Reviews/labeled_english_reviews.csv\" /content/GeneratedReviewsDetection/data/val_val.csv"
      ],
      "metadata": {
        "id": "kAY-sew6YnUc"
      },
      "id": "kAY-sew6YnUc",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/GeneratedReviewsDetection && python3 ./src/train.py"
      ],
      "metadata": {
        "id": "VVddPqwOYtd5",
        "outputId": "92816743-c2c4-4275-ec15-cfcd94eacefd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VVddPqwOYtd5",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 23:34:48.406693: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 23:34:48.406751: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 23:34:48.406789: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 23:34:48.415045: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-29 23:34:49.593241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['transformer.h.1.attn.attention.bias', 'transformer.h.5.attn.attention.bias', 'transformer.h.9.attn.attention.bias', 'transformer.h.3.attn.attention.bias', 'transformer.h.7.attn.attention.bias', 'score.weight', 'transformer.h.11.attn.attention.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Backbone type: EleutherAI/gpt-neo-125M\n",
            "Training on device:  cuda\n",
            "Learning rate: 0.0001\n",
            "EPOCH: 1..\n",
            "Training..\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GeneratedReviewsDetection/./src/train.py\", line 148, in <module>\n",
            "    train_gpt(1000)\n",
            "  File \"/content/GeneratedReviewsDetection/./src/train.py\", line 81, in train_gpt\n",
            "    for i, data in enumerate(train_dataloader, start = 1):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/GeneratedReviewsDetection/src/dataset.py\", line 24, in __getitem__\n",
            "    encoded_input = self.tokenizer(text, return_tensors='pt')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 2520, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 2578, in _call_one\n",
            "    raise ValueError(\n",
            "ValueError: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd GeneratedReviewsDetection/ && python3 /content/GeneratedReviewsDetection/src/dataset.py"
      ],
      "metadata": {
        "id": "alBFkHcLbPm1",
        "outputId": "af780afb-9ad5-4482-bd16-5fae1bad2a11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "alBFkHcLbPm1",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 23:33:56.197969: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 23:33:56.198026: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 23:33:56.198066: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 23:33:56.206470: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-29 23:33:57.352038: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "{'input': {'input_ids': tensor([[   40,   423,  7090,    12, 13664,    11,  6546,    11,  3124,    12,\n",
            "         37182,  4190,   290,  1842,   262,  1254,   262,  5870,    40, 26006,\n",
            "          4806,  4241,  3607,   340,    13,  2329,   779,   257, 29550, 43110,\n",
            "          2033,    13,  2011,  4190,  5300,  2705,   290,  3313,  2584,   706,\n",
            "           779,    13,   770,   468,   257,   845, 15497, 21212,   290,   257,\n",
            "          1310,  2925,   257,   890,   835,    13,   314,  1101,  2407, 10607,\n",
            "           351,   262,  2482,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, 'label': 0}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}